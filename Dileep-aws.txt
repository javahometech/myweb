
AWS : Amazon webservices ..

It is one of the cloud service provider in the market.

AWS is managed by amzaon.com

cloud computing : services / resources ===>> online ==>> ondemand ==>> through ==>> internet.

services / resources ===>> servers , database, backup , storage , network ..etc

cloud ==>> 1 linux server ( ec2 instance ) ==>> less than one minit.

1 liinux ec2 instance ===>> 2 years ==>> bill pay ==>> pay as you go.

30 % and 70 %

why cloud computing ??

Datacenters : Group of physical servers ==>> manage ==>>> single place ==.ONPREMISE INFRASTRUCTURE

Buildings , space , hwardware , cabling , swithches , hubs , routers , manpower , powersupply , field engineers ,

o.s , application , database , storage , backup ..etc. ==>>> APP ==>> EU.

1. time 2. money 

Physical linux server ==>> mininmum 3 months

70 % and 30 %

AWS , Azure , GCP , OC , IC , SC , AC , RC ,..etc

Cloud service models : 3 types.

1. IAAS : Infrastructure as a service.==>> Admins ===>> infrastructure ==>> network , storage , servers , backup ,databse..

2. PAAS : Platform as a service.===>> Developers ==>> code ==>>> java , .net , python.

3. SAAS : Software as a service ===>> Endusers ==>> money pay ==>> app ( client) use. ==>> 24/7 ==>> online

IAAS ==>>> ADMIN.

Types of clouds: 3 types.

1. public cloud :

A cloud which is directly exposed to internet then it is called public cloud.

2. private cloud :

A cloud which is not directly exposed to internet then it is called private cloud

3. Hybrid cloud :

It is a combination of public and private cloud then it is called hybrid cloud.

====================================================================================

AWS : 

1. Region  ==>> it is a geographical location in the cloud.==>> logical data centers.

2. Availabilty zone ==>>> High availabilty ( HA) ==>> physical / local data centers

group of local data centers is called region.

region ==>> 22 regions.

============================================================================================

============================================================================================

AWS : keycomponents :

1. VPC

2. Internetgateway

3. subnets

4. routing tables

5. security group.

====================================

1. VPC : virtual private cloud.

1. It is an isolated network in the cloud.

2. Vpc is region specific.

3. Every region has one default vpc. ==>>> do not delete this.

4. Suupose if we accidentally delete this we will create support case to AWS people. 

5. vpc is free of cost.

6. we will create 5 vpc's per region ( AWS free-tier ).

7. Vpc has a CIDR notation ==>> /16.

====================================================

2. Internet gateway :

1. It is the gateway to all endusers to access application.

2. Intergateway is the region specific.

3. Every region has one deafult internetgateway ==>> do not delete this..

4. Internet gateway is the free of cost.

5. Internetgateway also has a CIDR notation ==>> 0.0.0.0/0

6. We will create multiple internetgateways under one VPC.

7. Internetgatway is attached to VPC and routingtables.

=================================================================================

3. subnets :

1. It is a smaller network inside VPC.

2. We will create multiple subnets under one VPC.

3. subnets are availability zone specific.

4. subnets are also having cidr notattion ==>> /24

5. subnets are free of cost.

6. subnets are attached to routing tables.

7. Every region has multiple subnets.

8. every region has default subnets ===>> do not delete this.

==================================================================================

4. routing tables :

1. It is virtual router in the cloud.

2. The main purpose of routing tables is to communicate with the diffrent networks.

3. Routing tables are region specific.

4. Routing tables are free of cost.

5. Every region has one default routing table ==>>> do not delete this.

5. when ever we create a vpc then automatically aws implicitely creates a routing table ==>> main routing table.

6. we will also create our own routing tables ===>> custom routing tables.

7. routing tables are attached to internetgateway and subnets.

=========================================================================

5. security group :

1. it is a virtual firewall at ec2 instance level.

2. It conatins set of rules..( ssh , http ,https , mysql ,alltraffic...etc)

3. security group ==>> source ==>> 3 fields

1. anywhere 2. custom 3. myip

4. security groups are region specific.

5. security groups are free of cost.

6. Every region has one default security group ===>>> do not delete this.

7. Security groups has inboundrules and outboundrules.

=========================================================================================================

public Ipaddress : Ec2 instance to login and application given to enduser.

it is visible in AWS console dash board only..

Ec2 instance ==>>> stop and start ==>> public Ipaddress will automatically changed ==>> because it is dynamic.

public ip is dynamic ==>>> application ==>> EU..==>> business impact ..

To over come this ==>> ELAstic IPaddress..


private IPaddress : It is used to internal communication.

it is visible in AWS console dash board and ec2 instance.

Ec2 instance ==>>> stop and start ==>> private Ipaddress will not be changed ==>> because it is static.


Elastic IPaddress  ( real time ): It is similar to public IPaddress.

Ec2 instance to login and application given to enduser.

it is visible in AWS console dash board only..

Ec2 instance ==>>> stop and start ==>> Elastic Ipaddress will not be changed ==>> because it is static.

Elastic IPaddress ==>> purchasable one. ==>> bill..

===============================================================================


public IP address : 54.199.92.49 / 13.114.231.65

private IPaddress : 50.20.9.224 / 50.20.9.224

Elastic IP :  18.177.203.200 / 18.177.203.200

===========================================================================================


Public subnet : 

A subnet which is directly exposed to internet it is called public subnet.

internetgateway attached to routing table then this subnet is called public subnet.

public subnet : application instances and web servers..

these instances are accessed all endusers ==>>> these instances are having public Ip / elastic IP.

These instances are accessed via public ip /elastic IP address..


private subnet :

A subnet which is not directly exposed to internet it is called private subnet.

internetgateway not attached to routing table then this subnet is called private subnet.

private subnet : database , backup , storage ..etc

These instances are not accessable to enduser. 

these instances are not having public Ip / Elastic IP..

These instances are not accessed via public or elastic IP.

These instances are accessed only through Private Ip address only..

===================================================================================

===========================================================================================


Public subnet : 

A subnet which is directly exposed to internet it is called public subnet.

internetgateway attached to routing table then this subnet is called public subnet.

public subnet : application instances and web servers..

these instances are accessed all endusers ==>>> these instances are having public Ip / elastic IP.

These instances are accessed via public ip /elastic IP address..


private subnet :

A subnet which is not directly exposed to internet it is called private subnet.

internetgateway not attached to routing table then this subnet is called private subnet.

private subnet : database , backup , storage ..etc

These instances are not accessable to enduser. 

these instances are not having public Ip / Elastic IP..

These instances are not accessed via public or elastic IP.

These instances are accessed only through Private Ip address only..

===================================================================================

NAT instance : Network address translation.

The main purpose of NAT instance is to grant or provide internet access to privatesubnet.

In general ==>>> database , backup , storage instances are no need of internet access..

private subnet : database , backup , storage ..etc ==>> update or upgrade ==>>> then these instances required internet access..

NAT instance thumbrule :

NAT instance must be launched in public subnet.

inbound rules / inbound access / inbound traffic ==>> internet ==>> internetgatway to ec2 instance

outbound rules / outbound access / outbound traffic ==>> internet ==>> ec2instance to  internetgatway

NAT follows outbound rules..

NAT instance ==>> launch instance ==>>> community AMI's ===>> search ==>>> nat ===>> no .of nat instances to display ==>> choose any one ==>>> normal ec2 instance creation steps..

select NAT instance ==>> actions ==>>> networking ==>> change source/destination check ==>> defaultly enable state. ===>>> we will do this desable ==>> stop ( check box ==>> check).

==>> first NAt instance ===>> Db instance ==>> SSH configuration. ==>> now you are in db instance..

ping google.com 

ping gmail.com

ping fb.com

==>>> ping success...

========================================================================================

========================================================================================

NATGATEWAY : to grant or provide internet access to private subnet.

NATgateway also follows outbound traffic..

public subnet : web servers

privatesubnet : database , storage , backup , ... ( publicly not accessable) -->> no public IP i.e private Ip

NATgateway : high availability and it is maintaintained by AWS.

NAt instance -->> not having  high availability and it is maintained by us.

NAT instance also we make it as high availability  --->> script --->>> HA .

NAt instance must be launched in public subnet -->> community AMI's -->> search -->nat

Natgateway must be launched in public subnet.

Natgateway is the same process of infrastructure creating of NAT instance..

VPC --->>> NGVPC -->> 30.20.0.0/16

IGW -->> NGIGW -->> attach -->> NGVPC

create two subnets -->> 1. ngpublicsubnet 2. ngprivatesubnet

MRTB -->>attach -->>IGW and ngpublicsubnet

create one ec2 instance ( normal ) under public subnet.

create --->>NATGATEWAY --->> public subnet.

note : natgateway must having elastic IP 

CRTB --->>> 0.0.0.0/0 --->> natgateway and attach ngprivate subnet

create one more instance --->> under privatesubnet ( storage) --->>> autoassign publicip -->>desable

final : login into the public subnet instance -->> configure ssh configuration --->>>> login into storage instance with the help of private IP

ping google.com

ping success

=================================================================================

=================================================================================

VPC Wizards

Wizards simplifies our VPC, IGW , routing tables , subnets, security group and NAT and NATGATEWAYconfigurations.

Currently we have 4 types of wizards

VPC with public subnet

VPC with public and private subnet

VPC with Public and Private Subnets and Hardware VPN Access

VPC with a Private Subnet Only and Hardware VPN Access.

Hardware VPN Access :

VPN : virtual private network..

Hardware VPN Access : Network people -->>> create VPN create ==>>> link generate ===>> vpn link.

VPN link ==>> the purpose of vpn link to connecting the client's network..

Every project has one vpn link..

How to access the vpn link ???

vpn link ==>> click ==>>>> username and password ===>> second level security ===>>> RSA token ===>> 6 digits ( every one minit==>> change) ===>> after entering the 6 digits ==>> now you are in clients network..

username and password ==>>> networking people ==>> email to us..

How to access / connect application instances in your organization ???

Note : you must be connect with vpn link..

1. ramakrishna ==>> IBM ==>> client ==>> DBS ==>> singapore.

2. ramakrishna ==>> need to login into the AWS account.

3. Admin team ===>>> for ramakrishna they will create one aws account.

4. ramakrishna will login into the AWS account with username and passowrd. ==>>> second level security. ( MFA ==>> multifactor authentication).

second level security ==>>> 2 ways..

1. mobile number.===>> OTP ==>>> 6 digits number =>> enter ==>> now you are in AWS account.

2. we need to install mobile app ==>>> google authenticator ==>>> AWS account ==> QR code ==>> SCAN ==>> 6 digits number ==>> enter ==>> now you are in AWS account.

IMportant key point :

1. Jump servers / jump instances  / bastion host ===>> security.

every project has 5 to 7 jump servers.

2. Application instances ===>>> EU.

first you need to login into jump server ==>>> after that you need to login into application instances..


jumpserver ==>>> 192.168.5.10 ==>>> IPaddress ==>> through putty we will connect jumpserver.

now you are in jump server. ==>> through ssh we will connect application instances..

ssh -i /tmp/central.pem ec2-user@appinstanceIP( elastic / private ) ==>> enter ==>>> now you are in application instance.

============================================================================================================================


============================================================================================================================

vpc peering :

The main purpose of vpc peering is to communicate with different networks..

Senario :

application team ==>> 30.20.0./16

admin team ==>> 60.20.0.0/16

By making peering between these two teams ==>> files trasfter and remote userly application will install..

VPC peering thumbrule :

Both vpc's CIDR notations should not be collide to each other.

VPC peering not supported transitive peering.

vpc1 ==>>> vpc2 ==>> vpc3 ==>> vpc4

vpc1 should not communicate with vpc3

vpc2 should not communicate with vpc4.

VPC peering ==>> who is the requester and accepter ===>> we will specify..

key point : Both VPC CIDR notations are interchanged in both main routing tables..

Then these two vpc's in between  ==>>> vpc peering connection established.

VPC peering will be doing in 3 ways..

1. same region.

2. different region.

3. different accounts / cross accounts..

===============================================================================================

[root@ip-30-20-9-42 ec2-user]# history
    1  ping 60.20.6.13
    2  vi /tmp/plugins.pem
    3  chmod 700 /tmp/plugins.pem
    4  touch peer1
    5  scp -i /tmp/plugins.pem peer1 ec2-user@60.20.6.13:/home/ec2-user
    6  ls
    7  ssh -i /tmp/plugins.pem ec2-user@60.20.6.13
    8  history
[root@ip-30-20-9-42 ec2-user]#
[root@ip-30-20-9-42 ec2-user]#

====================================================================================================

Transite gateway :

The main purpose of Transite gateway is to communicate with different networks.

Transite gateway thumb rule :

Both vpc's CIDR notations should not be collide to each other.

Transitegateway supports transtive peering..

vpc1 ==>> vpc2 ==> vpc3 ==>> vpc4

create transitegatway ==>> when ever you created TGW ==>>> then automatically transitgateway routing tables will create.

next we will TGWattachments for every vpc (infrastructure)

key point : ALL VPC CIDR notations are interchanged in ALL main routing tables..

===========================================================================================

VPC end points : with out having publicip though acesss other aws services by vpc end points.. ( automatically routing table -->>>change)

private subnet --->> no internet access ---->>> NAT instance create --->>> privatesubnet --->> ec2 instance ( databse ) --->> s3 create buckets..

AWS --->> storage --->>s3 -->>> simple storage service ---> buckets --->>create -->> objects -->>upload , download ,delete , rename..

aws s3 ls 

aws s3 mb s3://s3ram2


ec2 instance --->>role add 

role -->>> aws --->>> service1 (ec2)--->> comminicate with other service2 (s3) --->>then we need a role..

==============================================================================================================================================

VPC flowlogs: Insfratructure --->> app --->>>not going to EU --->>>> trouble shoot  --->>> logs -->>. store -->> analysis

VPc --->>ec2 instance -->>app -->>install -->>EU

VPC -->> network issues --->>> logs --->>> generate -->> logs group --->>> AWS -->> s3 buckets 

s3 -->> simple storage service 

AWS --->> storage --->>s3 -->>> simple storage service ---> buckets --->>create -->> objects -->>upload , download ,delete , rename..

================================================================================================================================


remove_bucket: s3bhaskar006
[root@ip-10-20-10-208 ec2-user]# history
    1  ping gmail.com
    2  aws s3 ls
    3  aws s3 ls
    4  aws s3 ls
    5  aws s3 mb s3://s3bhaskar006
    6  aws s3 mb s3://s3bhaskar007
    7  aws s3 rb s3://s3bhaskar007
    8  aws s3 rb s3://s3bhaskar006
    9  history


======================================================================================

How to provide security to the VPC.

two ways :

1. security group

2. NACL ( network access control list )

1. security group :

It is a virual firewall at ec2 instance level.

It contains set of rules.

source have 3 optipons :

1. custom 2. Anywhere 3. MYIP

1. Custom : with in our organization network ( 10.20.5.0/16 )

2. Anywhere : all access our application

3.MYIP : wifi ==>> IPaddress but perticular Ip :  117.208.194.37/32

Inbound access : internet ==>> IGW to ec2 instance

Oubound access : internet ===>>> ec2 instance to IGW 

Security groups are statefull.

Security groups are sub service of ec2 intance level..

NACL : 

Network ACLs and its Characteristics

Network ACL is firewall acts at subnet level

When VPC is created NACL is implicitly created, this is called as default NACL

Default NACL allows all inbound and outbound traffic

Any subnet created is implicitly associated with default NACL

Multiple subnets can be associated with one NACL

One subnet can be associated with only one NACL

Every rule can be explicitly allowed or denied

Network ACLs are stateless, i.e. inbound traffic is controlled by inbound and outbound traffic is controlled by outbound rule.

We have options to block an ip address/network using NACL

===============================================================================================================================

AMI ==>>> Amazon machine image.

AWS gives lot of default AMI's

AMI ==>> It is a template , it contains the operating system and pre defined applications / softwares are installed on it.

AMI ==>>> BAckup 

we will create our own AMI's ==>> custom AMI's

By default all custom AMI's are private.

How to create our own AMI ??

select ec2 instance ==>>> Actions ==>> images and templates ==>> create image ==>> bhargavi ==>> AMI will created.

==>> we will create n no.of ec2 instances from one AMI.

==>> when we create our own AMI then automatically creates one snapshot.

===>> we create AMI's from snapshots.

===>> default snapshots are stored in S3 buckets..

==>> we will also copy AMI's and snapshots from one region to another region.

ec2 instance ==>> AMI

AMI ==>> EC2 instance

SNAPSHOT ==>>> AMI 

==========================================================================================================

EBS : elastic block storage.

it is a block level storage.

senario :

Application team ==>> request raise to admin team ( ours) ===>> 500 gb volume ==>>> linux ec2 instance( app123)==> file system create ==>>> app5 ==>> mount point create ==>>> app install.

EBS thumbrule :

ec2 instance and volume should be in same availability zone.

1. we need to create one ec2 instance in 2a ( AZ).

2. create volume ===>> 500gb ==>> in 2a ( AZ).

3. we will attach this volume to ec2 instance..

device naming convensions:

/dev/sda to /dev/sdp ==>> one ec2 instance ==>> we will create 16 volumes..

/dev/sda to /dev/sde ==>> o.s will internally use these 5 volumes..

we will create extranal volumes from /dev/sdf to /dev/sdp... ( 11 volumes)

after login into the ec2 instance ==>> /dev/xvdf to /dev/xvdp..

/dev/sdf ===>> /dev/xvdf 

after login into the ec2 instance ==>> follow the below steps..

1. fdisk -l ( o.s control )

2. lsblk ===>>> kernel identification.

3. mkfs.ext4 /dev/xvdf ===>>> creating the file system.

4. mkdir app5 ==>> creating the directory..

5. attaching a directory to the file system ==>>> mounting and app5 ==>> mount point.

mount -t ext4 /dev/xvdf app5

6. cat /etc/mtab

7. we will make as this filesystem to be permanante..

vi /etc/fstab

devicename mountpoint typeoffilesystem defaults 0 ( dump ) 0 ( checksequence)

/dev/xvdf /home/ec2-user/app5 ext4 defaults 0 0

esc shift:wq! ==>> save. 

8. cd app5

ls

lost + found 

touch {a..k}

reboot ..

=======================================================================

Note : EBS is persistant storage ( permanate storage.)

[root@ip-172-31-44-137 ec2-user]# history
    1  fdisk -l
    2  lsblk
    3  mkfs.ext4 /dev/xvdf
    4  mkdir app5
    5  mount -t ext4 /dev/xvdf app5/
    6  cat /etc/mtab
    7  vi /etc/fstab
    8  ls
    9  cd app5/
   10  ls
   11  touch {a..z}
   12  ls
   13  mkdir one two three four five sachin yuvi
   14  ls
   15  cd ..
   16  history
[root@ip-172-31-44-137 ec2-user]#
[root@ip-172-31-44-137 ec2-user]#

=================================================================

EBS ==>> volume ==>>> backup ==>> by using snapshot.

volume ==>> we will create snapshots from volume.

snapshots ==>>> we will create volume from snapshot.

we will take backup not only volume but also taking entire ec2 instance.

and also we will break ebs thumbrule by using snapshot..

keypint : we will increase the volume size but we can not down size the volume..

EBS : we also taking scheduled wise backup also.. by using life cycle manager..

Default snapshots are stored in S3 buckets..

==================================================================================

[root@ip-172-31-6-230 app200]# history
    1  fdisk -l
    2  lsblk
    3  mkdir app100
    4  mount -t ext4 /dev/xvdf app100/
    5  vi /etc/fstab
    6  ls
    7  cd app100/
    8  ls
    9  cd ..
   10  fdisk -l
   11  lsblk
   12  mkfs.ext4 /dev/xvdg
   13  mkdir app200
   14  mount -t ext4 /dev/xvdg app200
   15  cat /etc/mtab
   16  vi /etc/fstab
   17  ls
   18  cd app200/
   19  ls
   20  mkdir rama bharagavi pavan srinivas sehwag
   21  ls
   22  touch {1..20}
   23  ls
   24  history
[root@ip-172-31-6-230 app200]#
[root@ip-172-31-6-230 app200]#
==================================================================================================
******EBS Volume Types

1. General Purpose SSD (Solid State Disk)

2. Provisioned IOPS SSD

3. Throughput optimized HDD ( high definition disk )

4. Cold HDD

5. Magnetic

===================================================

***********Instance Store :

It Is a temporary store, data stored on this store is lost when we poweroff the Instance
Storage cost is very very cheap compared with EBS
Use this types to store temporary data.

=====================================================================

EC2 Instances (Purchase Options)

- On-Demand Instances

- Reserved Instances

- Spot requests

- Dedicated Hosts

- Scheduled Instances

========================================================================

**********Instance Types :

1. General purpose.

2. Compute optimized.

3. GPU optimized.

4. Memory optimized.

5. Storage optimized.


==================================================================

ec2 instance ( ex : t2.micro ===>. 1 cpu , 1 gb ram ) ==>> SBI app install ==>> EU 

after some days ==>> SBI app ==>>> incoming traffic increase ==>> CPU / DISK / NETWORK utilization high ==>. ec2 instance hung state.

at that time our application not going to enduser ===>. client ==>>> business impact.

To over come above senario we will increase the ec2 instace size ( hard ware resources to increase) ===>>> vertical scaling.

******How to increase our ec2 instance size ??

*******How to change ec2 instance type ??

***********how to change you ec2 instance resize ???

1. you need to stop the ec2 instance.

2. you will increase your ec2 instance size .


EC2 Instance resizing

Instance resizing is a way to scale up or scale down our EC2 instances.

Note: We must stop the instance before resizing.

Select Instance → Actions → Instance Settings → Change Instance Type.

========================================================================================

How to protect our ec2 instances from accidental deletions ??

1. select ec2 instance ===>>. Actions ==>>> instance settings ==>>> change termination protection ==>> enable.

========================================================================================

EC2 Userdata :

Using this option we can run scripts at EC2 launch time. There are many use cases for this, for
example we wanna configure our servers with chef/puppet we need chef/puppet agents on our
machines this can be achieved using userdata.

Example: Using user data

1. Install apache server

2. Start and enable apache server

3. Deploy a sample html file on the apache server

Launch EC2 and at step 3 under user data paste this script

#! /bin/bash
yum install httpd -y
service httpd start
chkconfig httpd on
echo "<h1> User data example </h1>" > /var/www/html/index.html

Note: Do not explicitly mention sudo, all the scripts in user data runs internally using sudo.

===================================================================================================

ELB : elastic load balancer..

The main purpose of elb is to distribute the incoming traffic to the our application.

ELB maintains the high avaibility of our application.

ELB thumbrule :

EC2 instances must be in different availability zones..

Ec2 ( 1a ) ==>>> orders app install

EC2 ( 1b) ===>>> payments app install

ELB supports both intranet and internet facing..

ELB is region region specific.

ELB ==>> security ==>>> security group.

ELB supports both http and https protocalls..

http ==>> 80

https ==>> 443 

https ==>> with security -===>> SSL cirtificate upload.

AWS ==>> aws control manager ==>>> request raise to cyber security team ===>> ssl cirtificate link generate==>>> email to aws control manager.===>> forward that email to us.

ELB suports SSL cirtificate termination.

ELB does health check on healthy instances only ..

ELB does not health check on un healthy instances..

health check ==>>> incoming traffic to distribute

healthy instances ==>>> instances up and running state.

un healthy instances ==>>> instances down and not running state.

If ELB finds an unhealthy instance then automaticaly elb taken out of the rotation.

If ELB finds an unhealthy instance to be healthy instance then ELB bring them automatically into rotation.

ELB ==>>> 3 types.

1. CLASSIC LOADBALANCER ( CLB)

2. APPLICATION LOADBALANCER ( ALB)

3. NETWORK LOADBALANCER ( NLB).

=====================================================================

1. CLASSIC LOADBALANCER ( CLB)

1. we need to take two instances in different availabilty zones.

ec2 ( 1a ) ===>> orders app install

ec2 ( 1b ) ===>> payments app install

2. we need to attach these two instances to CLB.

3. DNS link ===>> browser paste it and refresh it.. ==>> orders / payments..

4. CLB routemap to ipaddress and port based

=======================================================================================

ELB ==>> stickyness should be desable ==>>> incoming traffic to distribute.

ELB ==>>> cross zone load balancing should be enable..

=====================================================================

2. Application load balancer ( ALB )

ALB : Path based routing / routemaping.

we need to take two instances in diffrent availability zones.

1. ec2 ( 1a) ===>>> orders app install

we need to login ec2 instance manually ===>>> install http application ===>> yum install -y httpd

service httpd start ( starting the service of httpd )

cd /var/www/html

mkdir orders 

cd orders 

vi index.html ==>> orders html code 

public Ip :80/orders ===>> path

2. ec2  ( 1b )===>>> payments app install

we need to login ec2 instance manually ===>>> install http application ===>> yum install -y httpd

service httpd start ( starting the service of httpd )

cd /var/www/html

mkdir payments

cd payments

vi index.html ==>> payments html code 

public Ip :80/payments ===>> path

==============================================================================================================

ALB : we need to create target groups 

Each application has their own target group 

orders ( 1a) ===>> target group

payments ( 1b ) ===>> target group

Attaching this target groups to ALB.

ALB : ==>>> perticular path ===>>> we will apply the conditions based on the target groups.

Specify ==>> default target group ===>> which target group ( orders / payments )

if /orders* then forward to orders target group. ===> adding the rules.

if /payments* then forward to payments target group. ===> adding the rules.

ALB ===>>>create ===> DNS LINK/orders ==>>> orders app ==>>EU.

DNS LINK/payments ==>>> payments app ==>>EU.

================================================================================================================================

ALB history :

[root@ip-172-31-30-198 orders]# history
    1  yum install -y httpd
    2  service httpd start
    3  cd /var/www/html/
    4  ls
    5  mkdir orders
    6  cd orders/
    7  vi index.html
    8  history
[root@ip-172-31-30-198 orders]#
[root@ip-172-31-30-198 orders]#

========================================================================
CLB VS ALB :

CLB :

1. Ipand port based route mapping

2. No target groups

3. There are no rules and conditions.

4. It is 4 th layer in OSI model

5. DNS link ==>> route map

ALB :

1. PAth based route mapping

2. Target groups are available here

3. rules and conditions are applied here.

4. It is the first layer in OSI model.

5. DNS link/path  ==>> route map.

=========================================================================================================

S3 : simple storage service.

The purpose of s3 is storage.

S3 : object level storage.

S3 : objects ==>>> stored as  key , value pair .

S3 is global specific.

S3 ==>> objects are stored in buckets..

we will create 100 buckets per region.

22 * 100 ===>> 2200 buckets ==>>> one aws a/c.

Each bucket has the storage limit ===>> 10 TB.

2200 * 10 ==>> 22000 TB ==>>> one aws a/c.

Buckets ==>>> objects ==> upload , download , delete , rename , makepublic, copy , move , folders....etc..

buckets ==>>>> objects ===>>> manintaining the versioning .

buckets ==>>> versioning should be enable..

S3 has the storage classes.

there are 4 types of stoarge classes in S3.

1. standard : regularly. ==>>> default stoarge class..

2. standard IA : Infrequent access ==>>> 3 months / 6 months / ..etc.

3. Reduced redundency : 2 yeraly once..

4. Glaciour : artifcats : backup ===>> after some time ===>> objects are automatically deleted.

S3 has lifecycle rules :

these lifecycle rules are applied on the S3 storage classes.

the objects are moving from one storage class to another class. ==>>> s3 life cycle rules..

S3 : CRR / DR

CRR : cross region replication / DR ==>> desauster recovery management.

singapore region ( bucket1) and sydney region ( bucket2) 

I will add some files in singapore region bucket then automatically reflect in  sydney region bucket.

CRR ==>>> High availability and backup..

1. verioning shulod be enabled in both buckets..

2. both bucktes ==>> make public.

3. we need to create role.

bucket1 will communicate with another bucket then we need to create role.

S3 : static website hosting ..

Senario:

Developers request raise to admin team ( ours)

can please test this application ( sbi -->> HL) is statically hosted or not in dev environment.

DEV / QA / UAT / PROD...>> environments..

S3 : important key point ==>>> API's play a key role in s3.

API's ==>>> 2 types ==>> SOAP and RESTFULL..

default snapshots are stored in s3 buckets..

S3 buckets ==>>> vpc end points , vpc flowlogs, elb logs..

S3 : how much data transfer speed in every region.

S3 ==>>> objects level ===>> locking..

S3 ==>>> objects level ===>> encrypt.

======================================================================================================

EFS : elastic file system.

Linux --->> 2 instnaces -->>> ssh configure --->>> file transfer ( SCP) and remote user login -->>> app -->> install.

EFS : 2 instances --->> no need to configure -->> SSH ==>> file tranfers. ( no need to use SCP command)

EFS : linux ===>> NFS ( network file system ) -->>> network level mount point 

EFS : elastic file system ===>>> network file stystem .---->> network level mount point

EFS ---->>> common mount point ===>>> 2 instances --->> network level mount point ===>>> we need to create common directory in two instances.

first ec2 ( ramakrishna) --->> second ec2 ( ramakrishna)

xyz --->>automatically goes to second ec2 instance xyz

EFS : security ==>> security groups..

EFS : thumb rule

1. Ec2 instances must be in diffrent availability Zones.

2. 2 instances -->> common steps like below.

1. efs package install

2. create one directory ===>> mkdir ramakrishna ===>> 2.1 ===>> create elastic file system.

3. mount point create. ( network level mount point)

4. cd ramakrishna -->> touch {1..9}


second instance ===>> cd ramakrishna

ls

9 files --->> visible.


======================================================================================

EFS history :

[root@ip-172-31-2-241 ramakrishna]# history
    1  yum install -y amazon-efs-utils
    2  mkdir /ramakrishna
    3  sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport fs-7ae54e42.efs.ap-southeast-2.amazonaws.com:/ /ramakrishna
    4  df -h
    5  cd /ramakrishna/
    6  touch {a..z}
    7  mkdir one sachin yuvi two
    8  ls
    9  ls
   10  history
[root@ip-172-31-2-241 ramakrishna]#
[root@ip-172-31-2-241 ramakrishna]#

=======================================================================================================================

===>> FAQ ==> EBS vs S3 VS EFS 


************* EBS : block level storage  ( ec2 instance and volume should be same AZ)

1. mount points .

2. SNAPSHOTS

mount points ==>>> application install

3. data encryption is available.

4. No lifecyclerules ===>>> backup ==>> lifecycle manager.

5. EBS ==>> volume types.

6. No storage classes available here
=================================================

S3  : object level storage

1. Buckets ( No need of ec2 instances.)

2. CRR ( cross region replication )

3. BUCKETS ==>> storing the objects only

3. data encryption is available.

4.  lifecyclerules are available.

5. Default snapshots are stored s3 buckets.

6. to see the data transfer speed in all regions..

7. S3 has storage classes

8.  we donot install application here

9. static websites are hosting here.

=============================================================

EFS : Network level storage ( Ec2 instances must be diffrent availabilty zones)

1. Network level mount points.

2. Backup also here ===>> if one instance terminated ===>> another instance ==>> backup available.

because of common mount point.

3. storing the files only.

3. data encryption is available.

4. No lifecyclerules

5. we donot install application here

======================================================================================



